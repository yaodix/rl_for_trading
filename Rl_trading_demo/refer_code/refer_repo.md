

### **入门--2017年**：始祖级别

* [q-trader](https://github.com/edwardhdlu/q-trader)
  * 架构设计
  * 训练方式
  * 缺点
    * 只做多、短视奖励、无仓位管理，与专业量化系统差距较大


可视化：


### *入门--AuroraLHL/DQN-for-Stock-Trading（中文友好）*

 **GitHub** **: https://github.com/AuroraLHL/DQN-for-Stock-Trading**

 **核心特点** **：**

* ✅  **中文README** **，适合中文用户**
* **✅ 详细的DQN原理讲解（软更新、经验回放等）**
* **✅ 使用PyTorch实现**
* **✅ 包含数据获取notebook**
* **✅ 可视化训练结果**
* **⭐ Stars: 11**
* **⚠️ 最后更新：2年前（2024年6月）**

 **适用场景** **：**

* **中文学习者**
* **DQN入门教学**

**2026 : 学生作业**

* [Deep-Q-Network-for-Finance](https://github.com/fraro01/Deep-Q-Network-for-Finance)
  * 参考了q-trader
  * 改进


### 进阶-- ebrahimpichka/DeepRL-trade（中等规模)

 **GitHub** **: https://github.com/ebrahimpichka/DeepRL-trade**

 **核心特点** **：**

* **✅ 实现PPO和DQN两种算法**
* **✅ 使用stable-baselines3的标准化实现**
* **✅ Gymnasium环境，支持Long/Cash/Short三种动作**
* **✅ YAML配置管理，便于实验**
* **✅ 500轮随机起始episodes评估，提供统计置信区间**
* **✅ 使用yfinance/Tiingo数据源，pandas-ta技术指标**
* **⚠️ 规模适中，适合学习和中等项目**

 **评估** **：你提到的这个项目** **实现度较好** **，有完整的训练-评估流程，适合从入门到进阶使用。**


### **Tahernezhad/Deep-Q-Learning-Stock-Trading（最新维护）**

 **GitHub** **: https://github.com/Tahernezhad/Deep-Q-Learning-Stock-Trading**

 **核心特点** **：**

* **✅ ** **最近仍在维护** **（最后更新：2026年1月）**
* **✅ 模块化PyTorch实现**
* **✅ 支持MLP/CNN/LSTM多种backbone**
* **✅ Double DQN + Dueling DQN选项**
* **✅ 软更新（Polyak）和硬更新切换**
* **✅ 完整的配置系统（config.py）**
* **✅ 自动结果记录和可视化**
* **⭐ Stars: 3（较新，社区小）**

 **适用场景** **：**

* **需要最新代码和依赖**
* **快速实验和迭代**
* **简洁的研究沙盒**

### 2026：工业级--终极框架

FinRL


### 其他

多只票按比例买卖，连续空间操作示例：https://github.com/tomgrek/RL-stocktrading

5个强化学习算法进行对比：https://github.com/sunnyswag/StockRL?tab=readme-ov-file

AC 算法操作两只票： https://github.com/tomgrek/RL-stocktrading

可视化：https://medium.com/data-science/visualizing-stock-trading-agents-using-matplotlib-and-gym-584c992bc6d4
